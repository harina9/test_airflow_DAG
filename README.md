### **Задача**
Создайте Airflow ETL процедуры, которые агрегируют данные погоды из внешних источников в базу.

### **Условия**
* Клонируйте проект.
* Создайте 2 DAG файла:
    1. Собирает данные по API и кладет их последовательно в сыром виде в специально созданную таблицу. Запускается каждую минуту.
    2. Записывает в специальную таблицу, поднялась ли средняя температура (за последние 10 минут), либо опустилась, либо осталась прежней относительно предыдущего промежутка в 10 минут. Запускается каждые 10 минут. 
        
        **Пример финальной таблицы**

        | date                | state | mean_temp |
        |---------------------|-------|-----------|
        | 2020-01-01 00:00:00 | same  | -3.2      |
        | 2020-01-01 00:10:00 | up    | -2.1      |
        | 2020-01-01 00:20:00 | down  | -2.2      |
* Расположите DAG файлы в директории *./dags*.
* Чтобы создать таблицы в базе данных внесите sql команды в файл *./sql/init.sql*.
* Предоставьте копию исходного кода в виде zip архива. 
* Проект должен запускаться через docker-compose.
* Передавайте api_key через параметры для безопасности.

### **Источник погодных данных**
https://www.weatherapi.com/api-explorer.aspx 
Можно использовать любой город.


### **Как запускать тестовую среду**
0. Установить docker и docker-compose https://docs.docker.com/engine/install/
1. Зайти в директорию проекта чрез командую строку 
2. Выполнить комнаду ```docker-compose up -d```
3. Заходим на http://localhost:8080/ 
4. ```USERNAME: airflow```
5. ```PASSWORD: airflow```

❗ Контейнеры занимают до 7 Гб на жестком диске и скачиваются около 20 мин.
